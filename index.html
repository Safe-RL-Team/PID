<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Julian Dralle">
<meta name="author" content="Jonas Loos">
<meta name="description" content="based on (An et al. 2021)">

<title>Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="blog_files/libs/clipboard/clipboard.min.js"></script>
<script src="blog_files/libs/quarto-html/quarto.js"></script>
<script src="blog_files/libs/quarto-html/popper.min.js"></script>
<script src="blog_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="blog_files/libs/quarto-html/anchor.min.js"></script>
<link href="blog_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="blog_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="blog_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="blog_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="blog_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="blog_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="blog_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script type="module" src="blog_files/libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="blog_files/libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
        <script type="text/javascript">
        window.PlotlyConfig = {MathJaxConfig: 'local'};
        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
        if (typeof require !== 'undefined') {
        require.undef("plotly");
        requirejs.config({
            paths: {
                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']
            }
        });
        require(['plotly'], function(Plotly) {
            window._Plotly = Plotly;
        });
        }
        </script>
        

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble</h1>
</div>

<div>
  <div class="description">
    based on <span class="citation" data-cites="an2021edac">(<a href="#ref-an2021edac" role="doc-biblioref">An et al. 2021</a>)</span>
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    Julian Dralle 
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            TU Berlin
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    Jonas Loos 
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            TU Berlin
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    <p>TODO: abstract</p>
  </div>
</div>

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="why-offline-rl" class="level3">
<h3 class="anchored" data-anchor-id="why-offline-rl">Why Offline-RL?</h3>
<p>Training of RL algorithms require <strong>active interaction</strong> with the environment. Training can become quite time-consuming and expensive. It can even be dangerous in safety-critical domains like driving or healthcare. A trial-and-error procedure is basically prohibited. We cannot as an example let an agent explore, make mistakes, and learn while treating patients in a hospital. That’s what makes learning from pre-collected experience so relevant. And fortunately we have already in many domains existing large datasets. Offline-RL therefore aims to learn policies using only these pre-collected data without further interactions with the environment.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/offline_rl.gif" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Online and Offline Reinforcement Learning</figcaption><p></p>
</figure>
</div>
</section>
<section id="what-properties-make-offline-rl-difficult" class="level3">
<h3 class="anchored" data-anchor-id="what-properties-make-offline-rl-difficult">What properties make offline-RL difficult?</h3>
<p>But offline RL comes with its own challenges. By far the biggest problem are so called <strong>out of distribution (OOD) actions</strong>. OOD actions refer to actions taken by an agent that fall outside the range of actions observed in the training dataset. State-action space can become so vast that the dataset cannot cover all of it. Especially narrow and biased datasets lack significant coverage and can lead to problems with OOD actions. For example, healthcare datasets are often biased towards serious cases. Only seriously ill people are getting treated, while healthier people are sent home untreated.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/ood_medicine.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>A naive algorithm might now conclude that treatment causes death, since there were no fatalities in the untreated (= healthy) patients. Choosing to not treat a severely sick patient is something that never happened in the data, since the doctor would thereby violate his duty of care. Not treating a sick patient is therefore an OOD action. Vanilla RL algorithm might heavily overestimate the Q-values of OOD state-action pairs.</p>
</section>
<section id="how-to-deal-with-ood-state-actions" class="level3">
<h3 class="anchored" data-anchor-id="how-to-deal-with-ood-state-actions">How to deal with OOD state-actions?</h3>
<p>“Avoid OOD state-actions!”, has been the approach of many offline RL algorithms. This can be achieved by regularizing the policy to be close to the behavior policy that was used to collect the data. A more recent approach is to penalize the Q-values to be more pessimistic as done in Conservative Q-learning for Offline RL (CQL). But if we use this approach we require either (a) an estimation of the behavior policy or (b) explicit sampling from OOD data points (difficult!). Further, we prohibit our agent to approach any OOD state-actions, while some of these might actually be good. Q-function networks <strong>do</strong> have the ability to generalize. It’s all about <strong>handling the uncertainty</strong> of these predictions. The agent might benefit from choosing some OOD data points which Q-values we can predict with high confidence. With SAC-N and EDAC An et al.&nbsp;(2021) found a way of <strong>effectively quantifying the Q-value estimates</strong> by an ensemble of Q-function networks. In this blog we will explore and explain them.</p>
</section>
</section>
<section id="the-basics" class="level2">
<h2 class="anchored" data-anchor-id="the-basics">The Basics</h2>
<section id="q-learning" class="level3">
<h3 class="anchored" data-anchor-id="q-learning">Q-Learning</h3>
<p>Like in standard reinforcement learning we want to find a policy <span class="math inline">\(\pi(a | s)\)</span> that maximizes the cumulative discounted reward <span class="math inline">\(\mathbb{E}_{s_t, a_t}[...]\)</span>. The model-free <a href="https://towardsdatascience.com/a-beginners-guide-to-q-learning-c3e2a30a653c">Q-learning</a> algorithm is a very common approach to learn the Q-function <span class="math inline">\(Q_{\phi}(s,a)\)</span> with-in a neural network.</p>
</section>
<section id="actor-critic-method" class="level3">
<h3 class="anchored" data-anchor-id="actor-critic-method">Actor-critic method</h3>
<p>In the standard deep actor-critic approach we use two networks: (1) a policy-based actor network and (2) a value-based critic network.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.mdpi.com/applsci/applsci-10-04236/article_deploy/html/images/applsci-10-04236-g005.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Structure of deep actor-critic RL</figcaption><p></p>
</figure>
</div>
<p>The critic network minimizes the Bellman residual. Note: In offline RL transitions are sampled from a static dataset <span class="math inline">\(D\)</span></p>
<!-- ![](figures/critic_formula.png) -->
<p><span class="math display">\[J_q(Q_\phi) := \mathbb{E}_{(s,a,s') \sim D} \left[ \left( Q_\phi(s,a) - \left ( r(s,a) + \gamma\ \mathbb{E}_{a'\sim\pi_\phi(\cdot|s')}[Q_{\phi'}(s',a')] \right)\right)^2 \right]\]</span></p>
<p>The actor network is updated in an alternating fashion to maximizes the expected Q-value.</p>
<!-- ![](figures/actor_formula.png) -->
<p><span class="math display">\[J_p(\pi_\phi) := \mathbb{E}_{s\sim D, a\sim\pi_\phi(\cdot|s)} \left[ Q_\phi(s,a) \right]\]</span></p>
</section>
<section id="conservative-q-learning" class="level3">
<h3 class="anchored" data-anchor-id="conservative-q-learning">Conservative Q-Learning</h3>
<p>As of 2021, Conservative Q-Learning <span class="citation" data-cites="Kumar2020ConservativeQF">(<a href="#ref-Kumar2020ConservativeQF" role="doc-biblioref">Kumar et al. 2020</a>)</span> is the state-of-the-art for offline RL. It uses a “simple Q-value regularizer” to prevent the overestimation of OOD actions.</p>
<!-- ![](figures/cql.png) -->
<p><span class="math display">\[\min_\phi J_q(Q_\phi)+\alpha(\mathbb{E}_{s\sim D, a\sim\mu(\cdot|s)}[Q_\phi(s,a)] - \mathbb{E}_{(s,a)\sim D}[Q_\phi(s,a)])\]</span></p>
<!-- TODO: check if it's really \mu and not \pi_\phi -->
<p>For each state, CQL computes a distribution over actions using a temperature parameter <span class="math inline">\(\alpha\)</span> that controls the amount of exploration. The distribution is a mixture of the behavior policy and the current Q-function. The closer <span class="math inline">\(\alpha\)</span> is to 1 the more conservative.</p>
<p>CQL will be used as the baseline.</p>
</section>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
</section>
<section id="soft-actor-critic-sac-n" class="level2">
<h2 class="anchored" data-anchor-id="soft-actor-critic-sac-n">Soft Actor-Critic (SAC-N)</h2>
<p>The paper introduces two new methods for offline RL. The first method is called SAC-N and is an extension of Soft Actor-Critic (SAC) <span class="citation" data-cites="Haarnoja2018SoftAO">(<a href="#ref-Haarnoja2018SoftAO" role="doc-biblioref">Haarnoja et al. 2018</a>)</span>, which is a popular off-policy actor-critic deep RL algorithm. SAC-N extends SAC by using the minimum q-value of N instead of two q-functions, i.e.&nbsp;critics. The idea behind using the minimum of more critics is that the resulting q-value is more pessimistic when the uncertainty is high. This prevents erroneously high q-values of OOD actions and therefore trains the actor to prefer safer actions.</p>
<p>The minimum of multiple critics approximates the true q-value minus a multiple of the standard deviation <span class="citation" data-cites="an2021edac">(<a href="#ref-an2021edac" role="doc-biblioref">An et al. 2021</a>)</span>:</p>
<p><span class="math display">\[ \mathbb{E}\left [\min_{i=1,...,N}Q_i\right] \approx m - \Phi^{-1}\left(\frac{N-\pi/8}{N-\pi/4+1}\right) \sigma \]</span></p>
<p>Where <span class="math inline">\(N\)</span> is the number of critics, <span class="math inline">\(Q_i\)</span> is the q-value of the <span class="math inline">\(i\)</span>-th critic, <span class="math inline">\(m\)</span> is the theoretical true q-value, <span class="math inline">\(\Phi\)</span> is the CDF of the standard gaussian distribution, and <span class="math inline">\(\sigma\)</span> is the standard deviation.</p>
<p>This is visualized in the diagram below, where q-value estimates over an exemplary action space are plotted.The black line is the theoretical true q-value and the grey area its standard deviation. The lightblue lines represent the critics, that try to approximate the true q-value. The bottom blue line is the minimum of the critics, that should, especially for a high number of critics, be roughly the true q-value minus a multiple of the standard deviation. You can use the slider to change the number of critics:</p>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb1" data-startfrom="0" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line -1;"><span id="cb1-0"><a href="#cb1-0" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="dv">0</span><span class="op">,</span><span class="dv">2</span><span class="op">,-</span><span class="dv">1</span><span class="op">,</span><span class="dv">0</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span><span class="dv">0</span><span class="op">,-</span><span class="dv">1</span><span class="op">,-</span><span class="dv">2</span><span class="op">,</span><span class="dv">0</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span><span class="dv">4</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">0</span><span class="op">,-</span><span class="dv">1</span><span class="op">,</span><span class="dv">0</span>]<span class="op">;</span></span>
<span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>stds  <span class="op">=</span> [<span class="dv">2</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span><span class="dv">4</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">3</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span><span class="dv">1</span><span class="op">,</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span><span class="dv">2</span>]<span class="op">;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>viewof num_critics <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">1</span><span class="op">,</span><span class="dv">50</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span><span class="dv">20</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span><span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"#critics: "</span>})<span class="op">;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">gaussianRandom</span>(mean<span class="op">=</span><span class="dv">0</span><span class="op">,</span> stdev<span class="op">=</span><span class="dv">1</span>) {</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> u <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">random</span>()<span class="op">;</span> <span class="co">// Converting [0,1) to (0,1]</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> v <span class="op">=</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">random</span>()<span class="op">;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> z <span class="op">=</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">sqrt</span>(<span class="op">-</span><span class="fl">2.0</span><span class="op">*</span><span class="bu">Math</span><span class="op">.</span><span class="fu">log</span>(u)) <span class="op">*</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">cos</span>(<span class="fl">2.0</span><span class="op">*</span><span class="bu">Math</span><span class="op">.</span><span class="cn">PI</span><span class="op">*</span>v)<span class="op">;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> z <span class="op">*</span> stdev <span class="op">+</span> mean<span class="op">;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">example_critic</span>() {</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [<span class="op">...</span><span class="bu">Array</span>(means<span class="op">.</span><span class="at">length</span>)<span class="op">.</span><span class="fu">keys</span>()]<span class="op">.</span><span class="fu">map</span>((i)<span class="kw">=&gt;</span><span class="fu">gaussianRandom</span>(means[i]<span class="op">,</span> stds[i]))<span class="op">;</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">toPlot</span>(data<span class="op">,</span> color){</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">line</span>(data<span class="op">.</span><span class="fu">map</span>((x<span class="op">,</span> i)<span class="kw">=&gt;</span>({<span class="st">"action space"</span><span class="op">:</span> i<span class="op">,</span> <span class="st">"q-value"</span><span class="op">:</span> x}))<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> <span class="st">"action space"</span><span class="op">,</span> <span class="dt">y</span><span class="op">:</span> <span class="st">"q-value"</span><span class="op">,</span> <span class="dt">stroke</span><span class="op">:</span> color})<span class="op">;</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>critics <span class="op">=</span> [<span class="op">...</span><span class="bu">Array</span>(num_critics)<span class="op">.</span><span class="fu">keys</span>()]<span class="op">.</span><span class="fu">map</span>(i<span class="kw">=&gt;</span><span class="fu">example_critic</span>())<span class="op">;</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">areaY</span>(means<span class="op">.</span><span class="fu">map</span>((x<span class="op">,</span>i)<span class="kw">=&gt;</span>({<span class="st">"action space"</span><span class="op">:</span> i<span class="op">,</span> <span class="dt">low</span><span class="op">:</span>x<span class="op">-</span>stds[i]<span class="op">,</span> <span class="dt">high</span><span class="op">:</span>x<span class="op">+</span>stds[i]}))<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> <span class="st">"action space"</span><span class="op">,</span> <span class="dt">y1</span><span class="op">:</span> <span class="st">"low"</span><span class="op">,</span> <span class="dt">y2</span><span class="op">:</span> <span class="st">"high"</span><span class="op">,</span> <span class="dt">fill</span><span class="op">:</span> <span class="st">"#ddd"</span>})<span class="op">,</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>      <span class="op">...</span>(critics<span class="op">.</span><span class="fu">map</span>(x<span class="kw">=&gt;</span><span class="fu">toPlot</span>(x<span class="op">,</span> <span class="st">"lightblue"</span>)))<span class="op">,</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">toPlot</span>([<span class="op">...</span><span class="bu">Array</span>(means<span class="op">.</span><span class="at">length</span>)<span class="op">.</span><span class="fu">keys</span>()]<span class="op">.</span><span class="fu">map</span>(i<span class="kw">=&gt;</span><span class="bu">Math</span><span class="op">.</span><span class="fu">min</span>(<span class="op">...</span>critics<span class="op">.</span><span class="fu">map</span>(x<span class="kw">=&gt;</span>x[i])))<span class="op">,</span> <span class="st">"blue"</span>)<span class="op">,</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">toPlot</span>(means<span class="op">,</span> <span class="st">"black"</span>)<span class="op">,</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  ]<span class="op">,</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  <span class="dt">y</span><span class="op">:</span> {</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="dt">domain</span><span class="op">:</span> [<span class="op">-</span><span class="dv">10</span><span class="op">,</span><span class="dv">10</span>]<span class="op">,</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="dt">label</span><span class="op">:</span> <span class="st">"q-value"</span><span class="op">,</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  }<span class="op">,</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="dt">x</span><span class="op">:</span> {</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="dt">tickFormat</span><span class="op">:</span> x <span class="kw">=&gt;</span> <span class="st">""</span><span class="op">,</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>})<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-6" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-7" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-8" data-nodetype="expression">

</div>
</div>
</div>
</div>
<p>SAC-N already achieves notable performance and beats the previous state of the art, CQL, as will be shown in the <a href="#results">results section</a>. However, SAC-N requires a large number of critics, which comes with a high computational cost. Therefore, the paper introduces a second method, EDAC, that is more efficient.</p>
</section>
<section id="ensemble-diversified-actor-critic-edac" class="level2">
<h2 class="anchored" data-anchor-id="ensemble-diversified-actor-critic-edac">Ensemble-Diversified Actor Critic (EDAC)</h2>
<p><span class="citation" data-cites="an2021edac">An et al. (<a href="#ref-an2021edac" role="doc-biblioref">2021</a>)</span> found, that the performance of the policy learned by SAC-N decreases significantly, when the q-functions share a similar local structure. To reduce this, they introduce an ensemble gradient diversification term to the loss function of the ensemble of critics:</p>
<p><span class="math display">\[ \underset\phi{\text{minimize}}\ \ \frac{1}{N-1} \sum_{1\leq i\neq j \leq N} \langle \nabla_a Q_{\phi_i}, \nabla_a Q_{\phi_j} \rangle \]</span></p>
<p>It measures the cosine similarity between the q-function gradients and is minimized when the gradients for the critics are as different as possible. This, in turn, leads to a more diverse ensemble of critics, which is more robust against overestimation of OOD actions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/EDAC_gradient_diversification.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Illustration of the ensemble gradient diversification. The vector <span class="math inline">\(\lambda_iw_i\)</span> represents the normalized eigenvector <span class="math inline">\(w_i\)</span> of <span class="math inline">\(\text{Var}(\nabla_a Q_{\phi_j}(s,a))\)</span> multiplied by its eigenvalue <span class="math inline">\(\lambda_i\)</span>. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption><p></p>
</figure>
</div>
<p>The full loss function of EDAC is then:</p>
<p><span class="math display">\[\nabla_{\phi_i} \frac{1}{|B|} \sum_{(s,a,r,s')\in B} \left (\left( Q_{\phi_i}(s,a) - y(r, s') \right) + \frac{1}{N-1} \sum_{1\leq i\neq j \leq N} \langle \nabla_a Q_{\phi_i}, \nabla_a Q_{\phi_j} \rangle \right)\]</span></p>
<p>where <span class="math inline">\(y(r, s')\)</span> is the target q-function<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, and <span class="math inline">\(B\)</span> is the batch of transitions.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>There are multiple implementations of EDAC and SAC-N available. <span class="citation" data-cites="an2021edac">An et al. (<a href="#ref-an2021edac" role="doc-biblioref">2021</a>)</span> published their implementation on <a href="https://github.com/snu-mllab/EDAC">GitHub</a>. It contains 9735 lines of python code over 93 files.</p>
<p>Another implementation is part of the Clean Offline Reinforcement Learning (CORL) <a href="https://github.com/tinkoff-ai/CORL">Repository</a>, which aims to provide single-file implementations of SOTA offline RL algorithms. Its EDAC implementation contains 639 lines of code in a single file. This makes it significantly easier to understand and modify. We therefore used it for some of our experiments and as a inspiration for our own implementation.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>We also <a href="https://github.com/JonasLoos/edac_reimplementation">implemented EDAC</a> from scratch and managed to achieve a code size of 371 lines, while adding additional features<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="figures/EDAC_reimplementation_halfcheetah.mp4"></video></div>
<p>This is our edac reimplementation on the halfcheetah task.</p>
<p>TODO: video description</p>
<p></p><div class="quarto-video"><video id="video_shortcode_videojs_video2" width="500px" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="figures/EDAC_reimplementation_walker2d-full-replay-230319-164301.mp4"></video></div> This is our edac reimplementation on the walker2d task.<p></p>
<p>TODO: video description</p>
<p>For a demonstration of a simple line-plot, see <span class="citation" data-cites="test-label1">(<a href="#ref-test-label1" role="doc-biblioref"><strong>test-label1?</strong></a>)</span>.</p>
<div class="cell" data-execution_count="1">
<div id="test-label1" class="cell-output cell-output-display">

<div>                            <div id="f59eadcc-3732-4397-917d-2a7136a7b44a" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("f59eadcc-3732-4397-917d-2a7136a7b44a")) {                    Plotly.newPlot(                        "f59eadcc-3732-4397-917d-2a7136a7b44a",                        [{"hovertemplate":"variable=Group: EDAC-D4RL - eval/reward_mean<br>Step=%{x}<br>value=%{y}<extra></extra>","legendgroup":"Group: EDAC-D4RL - eval/reward_mean","line":{"color":"#636efa","dash":"solid"},"marker":{"symbol":"circle"},"mode":"markers+lines","name":"Group: EDAC-D4RL - eval/reward_mean","orientation":"v","showlegend":true,"x":[11,67,123,179,235,291,347,403,459,515,571,627,683,739,795,851,907,963,1019,1075,1131,1187,1243,1299,1355,1411,1467,1523,1579,1635,1680],"xaxis":"x","y":[-7.191827495745069,-31.630119747480077,-26.01604240403602,648.5403934140011,2230.3681914902927,2496.1021711571566,3529.319872359528,3788.9648865302856,3847.558008609126,4081.3218940764295,4427.022591291778,5209.814485614904,5755.377458322516,5725.41189236465,6249.705033453381,5941.147526438264,5869.315588168673,7050.034912121393,7009.580584215716,7268.05029363611,7146.078890307355,7031.748134865328,7240.544383034362,7214.036294911362,7401.271435354343,7307.311063405458,7419.961277404835,7317.312166295378,7369.320318226045,7503.950082031106,7220.364646457332],"yaxis":"y","type":"scatter"},{"hovertemplate":"variable=Group: EDAC-D4RL - eval/reward_mean__MIN<br>Step=%{x}<br>value=%{y}<extra></extra>","legendgroup":"Group: EDAC-D4RL - eval/reward_mean__MIN","line":{"color":"#EF553B","dash":"solid"},"marker":{"symbol":"circle"},"mode":"markers+lines","name":"Group: EDAC-D4RL - eval/reward_mean__MIN","orientation":"v","showlegend":true,"x":[11,67,123,179,235,291,347,403,459,515,571,627,683,739,795,851,907,963,1019,1075,1131,1187,1243,1299,1355,1411,1467,1523,1579,1635,1680],"xaxis":"x","y":[-7.402046963260551,-84.68365553341621,-282.9247330137491,-80.07222524986321,-76.4095415734593,-10.381349397831675,-0.5163352851053276,-16.393740324911686,59.22118710565319,-12.372557914617548,44.86943008015631,60.36726842573957,72.80898054416545,50.600513303251866,2942.64222995802,722.4270100872538,766.5948199391627,6062.619186907393,6272.812475436871,6951.677336319645,6637.437071457427,5960.16498250416,6816.022492022086,6400.474286813075,7078.438349208797,6867.378169837827,7127.823401732091,6869.502609184527,6886.459591454254,7162.858603531412,6677.287674475787],"yaxis":"y","type":"scatter"},{"hovertemplate":"variable=Group: EDAC-D4RL - eval/reward_mean__MAX<br>Step=%{x}<br>value=%{y}<extra></extra>","legendgroup":"Group: EDAC-D4RL - eval/reward_mean__MAX","line":{"color":"#00cc96","dash":"solid"},"marker":{"symbol":"circle"},"mode":"markers+lines","name":"Group: EDAC-D4RL - eval/reward_mean__MAX","orientation":"v","showlegend":true,"x":[11,67,123,179,235,291,347,403,459,515,571,627,683,739,795,851,907,963,1019,1075,1131,1187,1243,1299,1355,1411,1467,1523,1579,1635,1680],"xaxis":"x","y":[-6.649679999910356,31.72201544869913,187.3525228538178,3057.5711923122813,6625.399466992443,6375.451088406224,6663.621200365842,7047.917095580802,7033.328212215516,7136.652773113213,7247.660251885999,7315.188497705664,7512.254648230528,7353.720648218016,7449.409187036588,7445.969963347789,7428.722315349917,7616.914789683683,7530.164941718071,7597.3919143745425,7536.587384008213,7776.260585381637,7535.448090299915,7581.117048950449,7636.109902226398,7679.9550880969855,7628.663692967518,7763.410486504045,7594.958639750014,7768.645775000949,7719.210035976948],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Step"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"value"}},"legend":{"title":{"text":"variable"},"tracegroupgap":0},"title":{"text":"Test Graph"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('f59eadcc-3732-4397-917d-2a7136a7b44a');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
<p>fig-cap example1</p>
</div>
</div>
<div class="cell" data-execution_count="2">
<div id="test-label2" class="cell-output cell-output-display">

<div>                            <div id="47b83b60-bdae-409b-bb32-132f3fb6a10a" class="plotly-graph-div" style="height:400px; width:800px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("47b83b60-bdae-409b-bb32-132f3fb6a10a")) {                    Plotly.newPlot(                        "47b83b60-bdae-409b-bb32-132f3fb6a10a",                        [{"line":{"color":"firebrick","dash":"dash","width":2},"name":"Line 1","x":[11,67,123,179,235,291,347,403,459,515,571,627,683,739,795,851,907,963,1019,1075,1131,1187,1243,1299,1355,1411,1467,1523,1579,1635,1680],"y":[-7.191827495745069,-31.630119747480077,-26.01604240403602,648.5403934140011,2230.3681914902927,2496.1021711571566,3529.319872359528,3788.9648865302856,3847.558008609126,4081.3218940764295,4427.022591291778,5209.814485614904,5755.377458322516,5725.41189236465,6249.705033453381,5941.147526438264,5869.315588168673,7050.034912121393,7009.580584215716,7268.05029363611,7146.078890307355,7031.748134865328,7240.544383034362,7214.036294911362,7401.271435354343,7307.311063405458,7419.961277404835,7317.312166295378,7369.320318226045,7503.950082031106,7220.364646457332],"type":"scatter"},{"line":{"color":"royalblue","width":2},"mode":"lines+markers","name":"Line 2","x":[11,67,123,179,235,291,347,403,459,515,571,627,683,739,795,851,907,963,1019,1075,1131,1187,1243,1299,1355,1411,1467,1523,1579,1635,1680],"y":[-7.402046963260551,-84.68365553341621,-282.9247330137491,-80.07222524986321,-76.4095415734593,-10.381349397831675,-0.5163352851053276,-16.393740324911686,59.22118710565319,-12.372557914617548,44.86943008015631,60.36726842573957,72.80898054416545,50.600513303251866,2942.64222995802,722.4270100872538,766.5948199391627,6062.619186907393,6272.812475436871,6951.677336319645,6637.437071457427,5960.16498250416,6816.022492022086,6400.474286813075,7078.438349208797,6867.378169837827,7127.823401732091,6869.502609184527,6886.459591454254,7162.858603531412,6677.287674475787],"type":"scatter"},{"line":{"color":"goldenrod","width":2},"name":"Line 3","x":[11,67,123,179,235,291,347,403,459,515,571,627,683,739,795,851,907,963,1019,1075,1131,1187,1243,1299,1355,1411,1467,1523,1579,1635,1680],"y":[-6.649679999910356,31.72201544869913,187.3525228538178,3057.5711923122813,6625.399466992443,6375.451088406224,6663.621200365842,7047.917095580802,7033.328212215516,7136.652773113213,7247.660251885999,7315.188497705664,7512.254648230528,7353.720648218016,7449.409187036588,7445.969963347789,7428.722315349917,7616.914789683683,7530.164941718071,7597.3919143745425,7536.587384008213,7776.260585381637,7535.448090299915,7581.117048950449,7636.109902226398,7679.9550880969855,7628.663692967518,7763.410486504045,7594.958639750014,7768.645775000949,7719.210035976948],"type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"tickfont":{"family":"Arial","size":12,"color":"rgb(82, 82, 82)"},"title":{"text":"Steps"},"showline":true,"showgrid":true,"showticklabels":true,"linecolor":"rgb(204, 204, 204)","linewidth":2,"ticks":"outside"},"yaxis":{"tickfont":{"family":"Arial","size":12,"color":"rgb(82, 82, 82)"},"title":{"text":"Average Return"},"showgrid":true,"zeroline":true,"showline":true,"showticklabels":true,"linecolor":"rgb(204, 204, 204)","linewidth":2,"ticks":"outside"},"margin":{"autoexpand":true,"l":100,"r":20,"t":110},"font":{"family":"Courier New, monospace","size":18,"color":"RebeccaPurple"},"title":{"text":"Test Graph"},"autosize":false,"width":800,"height":400,"showlegend":true,"legend":{"title":{"text":"Legend Title"}},"plot_bgcolor":"white"},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('47b83b60-bdae-409b-bb32-132f3fb6a10a');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
<p>fig-cap example2</p>
</div>
</div>

</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-an2021edac" class="csl-entry" role="doc-biblioentry">
An, Gaon, Seungyong Moon, Jang-Hyun Kim, and Hyun Oh Song. 2021. <span>“Uncertainty-Based Offline Reinforcement Learning with Diversified q-Ensemble.”</span> In <em>Neural Information Processing Systems</em>.
</div>
<div id="ref-Haarnoja2018SoftAO" class="csl-entry" role="doc-biblioentry">
Haarnoja, Tuomas, Aurick Zhou, P. Abbeel, and Sergey Levine. 2018. <span>“Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.”</span> In <em>International Conference on Machine Learning</em>.
</div>
<div id="ref-Kumar2020ConservativeQF" class="csl-entry" role="doc-biblioentry">
Kumar, Aviral, Aurick Zhou, G. Tucker, and Sergey Levine. 2020. <span>“Conservative q-Learning for Offline Reinforcement Learning.”</span> <em>ArXiv</em> abs/2006.04779.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Figure taken from <span class="citation" data-cites="an2021edac">An et al. (<a href="#ref-an2021edac" role="doc-biblioref">2021</a>)</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>TODO: maybe describe what the target q-function is<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Our fork of CORL for our experiments is also available on <a href="https://github.com/JonasLoos/CORL">GitHub</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>We added features like the continuation of training runs, and new critic ensemble reduction functions (instead of min) to our implementation.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script type="ojs-module-contents">
{"contents":[{"methodName":"interpret","cellName":"ojs-cell-1","inline":false,"source":"means = [0,2,-1,0,1,1,2,0,-1,-2,0,1,2,4,3,3,1,0,-1,0];\nstds  = [2,3, 2,1,2,3,2,3, 4, 2,3,4,2,1,3,2,1,2, 3,2];\nviewof num_critics = Inputs.range([1,50], {value:20, step:1, label: \"#critics: \"});\nfunction gaussianRandom(mean=0, stdev=1) {\n    let u = 1 - Math.random(); // Converting [0,1) to (0,1]\n    let v = Math.random();\n    let z = Math.sqrt(-2.0*Math.log(u)) * Math.cos(2.0*Math.PI*v);\n    return z * stdev + mean;\n}\nfunction example_critic() {\n  return [...Array(means.length).keys()].map((i)=>gaussianRandom(means[i], stds[i]));\n}\nfunction toPlot(data, color){\n  return Plot.line(data.map((x, i)=>({\"action space\": i, \"q-value\": x})), {x: \"action space\", y: \"q-value\", stroke: color});\n}\ncritics = [...Array(num_critics).keys()].map(i=>example_critic());\nPlot.plot({\n  marks: [\n      Plot.areaY(means.map((x,i)=>({\"action space\": i, low:x-stds[i], high:x+stds[i]})), {x: \"action space\", y1: \"low\", y2: \"high\", fill: \"#ddd\"}),\n      ...(critics.map(x=>toPlot(x, \"lightblue\"))),\n      toPlot([...Array(means.length).keys()].map(i=>Math.min(...critics.map(x=>x[i]))), \"blue\"),\n      toPlot(means, \"black\"),\n  ],\n  y: {\n    domain: [-10,10],\n    label: \"q-value\",\n  },\n  x: {\n    tickFormat: x => \"\",\n  }\n});\n"},{"methodName":"interpretQuiet","source":"shinyInput('num_critics')"}]}
</script>
<script type="module">
window._ojs.paths.runtimeToDoc = "../../..";
window._ojs.paths.runtimeToRoot = "../../../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>



</body></html>